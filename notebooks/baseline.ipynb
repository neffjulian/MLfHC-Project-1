{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"../data/mitbih_test.csv\", header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = df_train.groupby(187).first()\n",
    "sns.lineplot(data=example.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_train[187])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.loc[idx, list(range(187))].astype(np.float32)\n",
    "        y = self.df.loc[idx, 187].astype(np.int8)\n",
    "        return torch.tensor(X), torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "\n",
    "class MITDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size = 32, train_split=0.8, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        timeseries_full = TimeSeriesDataset()\n",
    "        train_length = int(self.train_split*len(timeseries_full))\n",
    "        val_length = len(timeseries_full) - train_length\n",
    "        self.train_set, self.val_set = random_split(timeseries_full, [train_length, val_length])\n",
    "        self.test_set = TimeSeriesDataset(test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=self.num_workers)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 dropout = 0,\n",
    "                 num_classes = 5,\n",
    "                 \n",
    "    ):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout, \n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "\n",
    "        x = x.unsqueeze(2)\n",
    "        out, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "        x = self.linear(out[:, -1, :])\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        test_loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"test_loss\", test_loss)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TimeSeriesDataset()\n",
    "x, y = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  15%|█▍        | 405/2737 [01:24<08:08,  4.77it/s, loss=1.08, v_num=17]"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "\n",
    "model = RNNModel(1, 64, 1)\n",
    "trainer = Trainer()\n",
    "\n",
    "mit = MITDataModule()\n",
    "trainer.fit(model, datamodule=mit)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "839a46e1465077c84b39be122588b4a3bd8a9d0460a9ee420f218244ce5714a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml4h')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
