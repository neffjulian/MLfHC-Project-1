{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "from src.dataset import MITDataModule\n",
    "from src.model import CNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= pd.read_csv(\"../data/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"../data/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "df_train, df_test = df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "/home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "   | Name      | Type                 | Params\n",
      "----------------------------------------------------\n",
      "0  | c1        | Conv1d               | 48    \n",
      "1  | c2        | Conv1d               | 656   \n",
      "2  | c3        | Conv1d               | 2.6 K \n",
      "3  | fc1       | Linear               | 39.0 K\n",
      "4  | fc2       | Linear               | 2.1 K \n",
      "5  | fc3       | Linear               | 33    \n",
      "6  | maxP      | MaxPool1d            | 0     \n",
      "7  | dropout   | Dropout              | 0     \n",
      "8  | flatten   | Flatten              | 0     \n",
      "9  | flatten0  | Flatten              | 0     \n",
      "10 | train_ROC | AUROC                | 0     \n",
      "11 | test_ROC  | AUROC                | 0     \n",
      "12 | valid_ROC | AUROC                | 0     \n",
      "13 | train_PRC | PrecisionRecallCurve | 0     \n",
      "14 | valid_PRC | PrecisionRecallCurve | 0     \n",
      "----------------------------------------------------\n",
      "44.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.4 K    Total params\n",
      "0.178     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 364/364 [00:13<00:00, 27.00it/s, loss=0.115, v_num=29] \n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "No `test_dataloader()` method defined to run `Trainer.test`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/julian/MLfHC/notebooks/cnn.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julian/MLfHC/notebooks/cnn.ipynb#ch0000002?line=6'>7</a>\u001b[0m mit \u001b[39m=\u001b[39m MITDataModule(df_train, df_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julian/MLfHC/notebooks/cnn.ipynb#ch0000002?line=7'>8</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, datamodule\u001b[39m=\u001b[39mmit)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/julian/MLfHC/notebooks/cnn.ipynb#ch0000002?line=9'>10</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:911\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule, test_dataloaders)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=905'>906</a>\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=906'>907</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=907'>908</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Use `trainer.test(dataloaders)` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=908'>909</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=909'>910</a>\u001b[0m     dataloaders \u001b[39m=\u001b[39m test_dataloaders\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=910'>911</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=674'>675</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=675'>676</a>\u001b[0m \u001b[39mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=676'>677</a>\u001b[0m \u001b[39mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=681'>682</a>\u001b[0m \u001b[39m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=682'>683</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=684'>685</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=685'>686</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=686'>687</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:954\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=948'>949</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtested_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=949'>950</a>\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=950'>951</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=952'>953</a>\u001b[0m \u001b[39m# run test\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=953'>954</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtested_ckpt_path)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=955'>956</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=956'>957</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtesting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1128\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1124'>1125</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_callbacks()\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1125'>1126</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_logging_functions()\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1127'>1128</a>\u001b[0m verify_loop_configurations(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1129'>1130</a>\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1130'>1131</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mprepare_data()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:42\u001b[0m, in \u001b[0;36mverify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=39'>40</a>\u001b[0m     __verify_eval_loop_configuration(trainer, model, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=40'>41</a>\u001b[0m \u001b[39melif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mTESTING:\n\u001b[0;32m---> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=41'>42</a>\u001b[0m     __verify_eval_loop_configuration(trainer, model, \u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=42'>43</a>\u001b[0m \u001b[39melif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mPREDICTING:\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=43'>44</a>\u001b[0m     __verify_eval_loop_configuration(trainer, model, \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:186\u001b[0m, in \u001b[0;36m__verify_eval_loop_configuration\u001b[0;34m(trainer, model, stage)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=181'>182</a>\u001b[0m \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=182'>183</a>\u001b[0m \u001b[39m# verify model has an eval_dataloader\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=183'>184</a>\u001b[0m \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=184'>185</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_loader:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=185'>186</a>\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo `\u001b[39m\u001b[39m{\u001b[39;00mloader_name\u001b[39m}\u001b[39;00m\u001b[39m()` method defined to run `Trainer.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_method\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=187'>188</a>\u001b[0m \u001b[39m# predict_step is not required to be overridden\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py?line=188'>189</a>\u001b[0m \u001b[39mif\u001b[39;00m stage \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: No `test_dataloader()` method defined to run `Trainer.test`."
     ]
    }
   ],
   "source": [
    "seed_everything(1234)\n",
    "\n",
    "\n",
    "model = CNNModel()\n",
    "trainer = Trainer(max_epochs = 1)\n",
    "\n",
    "mit = MITDataModule(df_train, df_test)\n",
    "trainer.fit(model, datamodule=mit)\n",
    "\n",
    "trainer.test(model, datamodule=mit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e9f8f0b0b81bd34d7674065dba92302069c4c563a79c2d0b6b68454c07c7580"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml4h')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
