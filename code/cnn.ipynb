{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.conv1 = nn.Conv1d(1, 16, 4)\n",
    "        #self.pool = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(187, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.binary_cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.binary_cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDataset(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        df_1= pd.read_csv(\"../data/ptbdb_normal.csv\", header=None)\n",
    "        df_2 = pd.read_csv(\"../data/ptbdb_abnormal.csv\", header=None)\n",
    "        df = pd.concat([df_1, df_2])\n",
    "\n",
    "        df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "        Y_train = torch.from_numpy(np.array(df_train[187].values).astype(np.int8))\n",
    "        X_train = torch.from_numpy(np.array(df_train[list(range(187))].values)[..., np.newaxis])\n",
    "\n",
    "        Y_test = torch.from_numpy(np.array(df_test[187].values).astype(np.int8))\n",
    "        X_test = torch.from_numpy(np.array(df_test[list(range(187))].values)[..., np.newaxis])\n",
    "\n",
    "        self.train_dataset = TensorDataset(X_train, Y_train)\n",
    "        self.test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.train_dataset)\n",
    "        return train_loader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.test_dataset)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:122: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "setup() got an unexpected keyword argument 'stage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/julian/MLfHC/code/cnn.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000008?line=1'>2</a>\u001b[0m dataset \u001b[39m=\u001b[39m NetDataset()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000008?line=2'>3</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000008?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel, datamodule\u001b[39m=\u001b[39;49mdataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=734'>735</a>\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=735'>736</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=736'>737</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=737'>738</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=738'>739</a>\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=739'>740</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=740'>741</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=741'>742</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=674'>675</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=675'>676</a>\u001b[0m \u001b[39mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=676'>677</a>\u001b[0m \u001b[39mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=681'>682</a>\u001b[0m \u001b[39m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=682'>683</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=684'>685</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=685'>686</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=686'>687</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=774'>775</a>\u001b[0m \u001b[39m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=775'>776</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=776'>777</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=778'>779</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=779'>780</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1138\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1135'>1136</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m\"\u001b[39m\u001b[39mon_before_accelerator_backend_setup\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1136'>1137</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39msetup_environment()\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1137'>1138</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_setup_hook()  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1139'>1140</a>\u001b[0m \u001b[39m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1140'>1141</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mrestore_checkpoint_after_pre_dispatch:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1438\u001b[0m, in \u001b[0;36mTrainer._call_setup_hook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1434'>1435</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mpre_setup\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1436'>1437</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatamodule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1437'>1438</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatamodule\u001b[39m.\u001b[39;49msetup(stage\u001b[39m=\u001b[39;49mfn)\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1438'>1439</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1440'>1441</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mpost_setup\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:474\u001b[0m, in \u001b[0;36mLightningDataModule._track_data_hook_calls.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py?line=468'>469</a>\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py?line=469'>470</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataModule.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m has already been called, so it will not be called again. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py?line=470'>471</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn v1.6 this behavior will change to always call DataModule.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py?line=471'>472</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py?line=472'>473</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py?line=473'>474</a>\u001b[0m     fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: setup() got an unexpected keyword argument 'stage'"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "dataset = NetDataset()\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model=model, datamodule=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e9f8f0b0b81bd34d7674065dba92302069c4c563a79c2d0b6b68454c07c7580"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('ml4h')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
