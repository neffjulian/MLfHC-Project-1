{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, batch_size=32, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(187, 1)\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = lr\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(self.flat(x.float()))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.binary_cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.binary_cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= pd.read_csv(\"../data/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"../data/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "Y_train = torch.from_numpy(np.array(df_train[187].values).astype(np.int8))\n",
    "X_train = torch.from_numpy(np.array(df_train[list(range(187))].values)[..., np.newaxis])\n",
    "\n",
    "Y_test = torch.from_numpy(np.array(df_test[187].values).astype(np.int8))\n",
    "X_test = torch.from_numpy(np.array(df_test[list(range(187))].values)[..., np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDataset(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = TensorDataset(X_train, Y_train)\n",
    "        self.test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.train_dataset)\n",
    "        return train_loader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.test_dataset)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "dataset = NetDataset()\n",
    "\n",
    "trainer = pl.Trainer(auto_scale_batch_size=True, auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:122: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "\n",
      "  | Name | Type    | Params\n",
      "---------------------------------\n",
      "0 | fc1  | Linear  | 374   \n",
      "1 | flat | Flatten | 0     \n",
      "---------------------------------\n",
      "374       Trainable params\n",
      "0         Non-trainable params\n",
      "374       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "/home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11641 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x187 and 1x187)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/julian/MLfHC/code/cnn.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000006?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel, datamodule\u001b[39m=\u001b[39;49mdataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=734'>735</a>\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=735'>736</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=736'>737</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=737'>738</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=738'>739</a>\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=739'>740</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=740'>741</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=741'>742</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=674'>675</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=675'>676</a>\u001b[0m \u001b[39mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=676'>677</a>\u001b[0m \u001b[39mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=681'>682</a>\u001b[0m \u001b[39m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=682'>683</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=684'>685</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=685'>686</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=686'>687</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=774'>775</a>\u001b[0m \u001b[39m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=775'>776</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=776'>777</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=778'>779</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=779'>780</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1199\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1195'>1196</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1197'>1198</a>\u001b[0m \u001b[39m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1198'>1199</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch()\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1200'>1201</a>\u001b[0m \u001b[39m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1201'>1202</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_dispatch()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1279\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1276'>1277</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mstart_predicting(\u001b[39mself\u001b[39m)\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1277'>1278</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1278'>1279</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mstart_training(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:202\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=199'>200</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart_training\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m\"\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=200'>201</a>\u001b[0m     \u001b[39m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=201'>202</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun_stage()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1289\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1286'>1287</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1287'>1288</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1288'>1289</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1319\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1316'>1317</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1317'>1318</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1318'>1319</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:234\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=230'>231</a>\u001b[0m data_fetcher \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mget_profiled_dataloader(dataloader)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=232'>233</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=233'>234</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(data_fetcher)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=235'>236</a>\u001b[0m     \u001b[39m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=236'>237</a>\u001b[0m     \u001b[39m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=237'>238</a>\u001b[0m     \u001b[39m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=238'>239</a>\u001b[0m     \u001b[39m# TODO(@carmocca): deprecate and rename so users don't get confused\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py?line=239'>240</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:193\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=189'>190</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=191'>192</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=192'>193</a>\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(batch, batch_idx)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=194'>195</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=196'>197</a>\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=197'>198</a>\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=85'>86</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=86'>87</a>\u001b[0m     optimizers \u001b[39m=\u001b[39m _get_active_optimizers(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizer_frequencies, batch_idx)\n\u001b[0;32m---> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=87'>88</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_loop\u001b[39m.\u001b[39;49mrun(split_batch, optimizers, batch_idx)\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=88'>89</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=89'>90</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_loop\u001b[39m.\u001b[39mrun(split_batch, batch_idx)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:215\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madvance\u001b[39m(\u001b[39mself\u001b[39m, batch: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=214'>215</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_optimization(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=215'>216</a>\u001b[0m         batch,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=216'>217</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_idx,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=217'>218</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizers[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_progress\u001b[39m.\u001b[39;49moptimizer_position],\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=218'>219</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_idx,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=219'>220</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=220'>221</a>\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=221'>222</a>\u001b[0m         \u001b[39m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=222'>223</a>\u001b[0m         \u001b[39m# would be skipped otherwise\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=223'>224</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39masdict()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:266\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[0;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=258'>259</a>\u001b[0m         closure()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=260'>261</a>\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=261'>262</a>\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=262'>263</a>\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=263'>264</a>\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=264'>265</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=265'>266</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(optimizer, opt_idx, batch_idx, closure)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=267'>268</a>\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=269'>270</a>\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=270'>271</a>\u001b[0m     \u001b[39m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=271'>272</a>\u001b[0m     \u001b[39m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=272'>273</a>\u001b[0m     \u001b[39m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:378\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=374'>375</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=376'>377</a>\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=377'>378</a>\u001b[0m lightning_module\u001b[39m.\u001b[39;49moptimizer_step(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=378'>379</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=379'>380</a>\u001b[0m     batch_idx,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=380'>381</a>\u001b[0m     optimizer,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=381'>382</a>\u001b[0m     opt_idx,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=382'>383</a>\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=383'>384</a>\u001b[0m     on_tpu\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_device_type \u001b[39m==\u001b[39;49m DeviceType\u001b[39m.\u001b[39;49mTPU \u001b[39mand\u001b[39;49;00m _TPU_AVAILABLE),\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=384'>385</a>\u001b[0m     using_native_amp\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mamp_backend \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39mand\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mamp_backend \u001b[39m==\u001b[39;49m AMPType\u001b[39m.\u001b[39;49mNATIVE),\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=385'>386</a>\u001b[0m     using_lbfgs\u001b[39m=\u001b[39;49mis_lbfgs,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=386'>387</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=388'>389</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1652\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1570'>1571</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1571'>1572</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1572'>1573</a>\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1579'>1580</a>\u001b[0m     using_lbfgs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1580'>1581</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1581'>1582</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1582'>1583</a>\u001b[0m \u001b[39m    Override this method to adjust the default way the\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1583'>1584</a>\u001b[0m \u001b[39m    :class:`~pytorch_lightning.trainer.trainer.Trainer` calls each optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1649'>1650</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1650'>1651</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py?line=1651'>1652</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:164\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=161'>162</a>\u001b[0m \u001b[39massert\u001b[39;00m trainer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=162'>163</a>\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(profiler_action):\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=163'>164</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py:339\u001b[0m, in \u001b[0;36mAccelerator.optimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=328'>329</a>\u001b[0m \u001b[39m\"\"\"performs the actual optimizer step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=329'>330</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=330'>331</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=335'>336</a>\u001b[0m \u001b[39m    **kwargs: Any extra arguments to ``optimizer.step``\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=336'>337</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=337'>338</a>\u001b[0m model \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=338'>339</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(model, optimizer, opt_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:163\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=160'>161</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule):\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=161'>162</a>\u001b[0m     closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=162'>163</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/autograd/grad_mode.py:26\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/autograd/grad_mode.py?line=22'>23</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/optim/adam.py:66\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/optim/adam.py?line=63'>64</a>\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/optim/adam.py?line=64'>65</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m---> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/optim/adam.py?line=65'>66</a>\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/optim/adam.py?line=67'>68</a>\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/optim/adam.py?line=68'>69</a>\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:148\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=134'>135</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=135'>136</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=136'>137</a>\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=139'>140</a>\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=140'>141</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=141'>142</a>\u001b[0m     \u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=142'>143</a>\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=143'>144</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=144'>145</a>\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=145'>146</a>\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=146'>147</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=147'>148</a>\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=148'>149</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=149'>150</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:160\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=158'>159</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=159'>160</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=160'>161</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:142\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=139'>140</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=140'>141</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mtraining_step_and_backward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=141'>142</a>\u001b[0m         step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=143'>144</a>\u001b[0m         \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=144'>145</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=145'>146</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=146'>147</a>\u001b[0m             )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:435\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=432'>433</a>\u001b[0m lightning_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtraining_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=433'>434</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mtraining_step\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=434'>435</a>\u001b[0m     training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mtraining_step(step_kwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=435'>436</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=437'>438</a>\u001b[0m \u001b[39mdel\u001b[39;00m step_kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py:219\u001b[0m, in \u001b[0;36mAccelerator.training_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=213'>214</a>\u001b[0m \u001b[39m\"\"\"The actual training step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=214'>215</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=215'>216</a>\u001b[0m \u001b[39mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.training_step` for more details\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=216'>217</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=217'>218</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=218'>219</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:213\u001b[0m, in \u001b[0;36mTrainingTypePlugin.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=211'>212</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=212'>213</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/julian/MLfHC/code/cnn.ipynb Cell 2'\u001b[0m in \u001b[0;36mNet.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=15'>16</a>\u001b[0m     x, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=16'>17</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=17'>18</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(y_hat, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "\u001b[1;32m/home/julian/MLfHC/code/cnn.ipynb Cell 2'\u001b[0m in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=10'>11</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflat(x\u001b[39m.\u001b[39;49mfloat()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/julian/MLfHC/code/cnn.ipynb#ch0000001?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/linear.py:93\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=91'>92</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=92'>93</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/functional.py:1690\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/functional.py?line=1686'>1687</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, tens_ops, \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/functional.py?line=1687'>1688</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/functional.py?line=1688'>1689</a>\u001b[0m     \u001b[39m# fused op is marginally faster\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/functional.py?line=1689'>1690</a>\u001b[0m     ret \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddmm(bias, \u001b[39minput\u001b[39;49m, weight\u001b[39m.\u001b[39;49mt())\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/functional.py?line=1690'>1691</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/julian/miniconda3/envs/ml4h/lib/python3.9/site-packages/torch/nn/functional.py?line=1691'>1692</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mmatmul(weight\u001b[39m.\u001b[39mt())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x187 and 1x187)"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e9f8f0b0b81bd34d7674065dba92302069c4c563a79c2d0b6b68454c07c7580"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('ml4h')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
